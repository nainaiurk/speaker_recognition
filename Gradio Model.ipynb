{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"elapsed":8601,"status":"error","timestamp":1691740110298,"user":{"displayName":"Nainaiu Rakhaine","userId":"14131965752020731977"},"user_tz":-360},"id":"nUXENWd1kSyA","outputId":"d9773650-6521-4fa0-a14f-dc1e6c205ced"},"outputs":[],"source":["import gradio as gr\n","import tensorflow as tf\n","import numpy as np\n","\n","SAMPLING_RATE = 16000\n","model = tf.keras.models.load_model('model.h5')\n","\n","class_names = ['Badhan_Halder', 'Imtiaz', 'Nainaiu', 'Ohee', 'Rejoyan']"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def audio_to_fft(audio):\n","    audio = tf.squeeze(audio, axis=-1)\n","    fft = tf.signal.fft(tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64))\n","    fft = tf.expand_dims(fft, axis=-1)\n","    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from pydub import AudioSegment\n","AudioSegment.converter  = \"C://ffmpeg/bin/ffmpeg.exe\"\n","AudioSegment.ffprobe   = \"C://ffmpeg/bin/ffprobe.exe\""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def convert_to_wav(input_file, output_file):\n","    audio = AudioSegment.from_file(input_file)\n","    if audio.frame_rate != 16000:\n","        audio= audio.set_frame_rate(16000)\n","    print(\"Frame rate: \",audio.frame_rate)\n","    audio.export(output_file, format=\"wav\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Preprocess function\n","def preprocess_custom_audio(path):\n","    if not path.endswith(\".wav\"):\n","        # Convert the audio file to .wav format\n","        wav_path = path.replace(path.split('.')[-1], 'wav')\n","        convert_to_wav(path, wav_path)\n","        if wav_path is None:\n","            return None\n","        path = wav_path\n","    audio = tf.io.read_file(path)\n","    audio, _ = tf.audio.decode_wav(audio, 1, SAMPLING_RATE)\n","    print('Audio path :',path)\n","    return audio"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Frame rate:  16000\n","Audio path : extra/abx.wav\n"]},{"data":{"text/plain":["<tf.Tensor: shape=(16000, 1), dtype=float32, numpy=\n","array([[0.],\n","       [0.],\n","       [0.],\n","       ...,\n","       [0.],\n","       [0.],\n","       [0.]], dtype=float32)>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["preprocess_custom_audio(\"extra/abx.mp3\")"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["def predict(audio_path):\n","    audio = preprocess_custom_audio(audio_path)\n","    audio = audio[len(audio)-SAMPLING_RATE:]\n","    audio_batch = np.expand_dims(audio, axis=0)\n","    audio_fft = audio_to_fft(audio_batch)\n","    predictions = model.predict(audio_fft)\n","    predicted_class_index = np.argmax(predictions[0])\n","\n","    # Get the predicted class label using the index\n","    if predictions[0][predicted_class_index] > 0.9:\n","        predicted_class_label = class_names[predicted_class_index]\n","    else:\n","        predicted_class_label = \"Unknown\"\n","    return predicted_class_label"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Audio path : audio/Badhan/badhon-2_001.wav\n","1/1 [==============================] - 0s 71ms/step\n","Predicted Speaker (With Noise): Badhan_Halder\n"]}],"source":["# Predict with added noise\n","predicted_speaker_with_noise = predict('audio/Badhan/badhon-2_001.wav')\n","print(\"Predicted Speaker (With Noise):\", predicted_speaker_with_noise)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\naina\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py:954: UserWarning: api_name predict already exists, using predict_1\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Running on local URL:  http://127.0.0.1:7869\n","Running on public URL: https://cae9c624142af3d68c.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["<div><iframe src=\"https://cae9c624142af3d68c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":38,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["Audio path : C:\\Users\\naina\\AppData\\Local\\Temp\\gradio\\bc348ec799d2058a74f66b4683924d068bb17adb\\Recording-0-100.wav\n","1/1 [==============================] - 0s 89ms/step\n","Audio path : C:\\Users\\naina\\AppData\\Local\\Temp\\gradio\\bc348ec799d2058a74f66b4683924d068bb17adb\\audio-13-100.wav\n","1/1 [==============================] - 0s 72ms/step\n","Audio path : C:\\Users\\naina\\AppData\\Local\\Temp\\gradio\\bc348ec799d2058a74f66b4683924d068bb17adb\\audio-0-100.wav\n","1/1 [==============================] - 0s 76ms/step\n","Audio path : C:\\Users\\naina\\AppData\\Local\\Temp\\gradio\\bc348ec799d2058a74f66b4683924d068bb17adb\\audio-6-88.wav\n","1/1 [==============================] - 0s 75ms/step\n","Audio path : C:\\Users\\naina\\AppData\\Local\\Temp\\gradio\\bc348ec799d2058a74f66b4683924d068bb17adb\\audio-6-88.wav\n","1/1 [==============================] - 0s 73ms/step\n"]}],"source":["examples = [\n","    ['extra/Nainaiu_001.wav','Speaker: Nainaiu'],\n","    ['extra/badhon_151.wav','Speaker: Badhon Halder'],\n","    ['extra/imti1_150.wav','Speaker: Imtiaz'],\n","    ['extra/ohee_158.wav','Speaker: Ohee'],\n","    ['extra/rejoyan_118.wav','Speaker: Rejoyan']\n","]\n","upiface = gr.Interface(\n","    fn=predict, \n","    inputs = gr.components.Audio(source=\"upload\", type=\"filepath\",format='wav',label=\"Upload audio file.\"),  # No explicit inputs required for microphone input\n","    outputs=gr.components.Label(label='Predicted Speaker',),  # Output label\n","    live=False,\n","    examples =  examples\n",")\n","miciface = gr.Interface(\n","    fn=predict, \n","    inputs = gr.components.Audio(source=\"microphone\", type=\"filepath\",format='wav',label=\"Use the microphone to capture audio.\"),  # No explicit inputs required for microphone input\n","    outputs=gr.components.Label(label='Predicted Speaker'),  # Output label\n","    live=False,\n","    examples =  examples\n",")\n","demo = gr.TabbedInterface(\n","    [miciface, upiface], \n","    [\"Microphone\", \"Upload File\"],\n","    title='''\n","    Speaker Recognition\\n\n","    Group 7\n","    ''',\n",")\n","# Launch the Gradio interface\n","demo.launch(share=True)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMnphDWRH+BOxSalrjz/OsI","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":0}
